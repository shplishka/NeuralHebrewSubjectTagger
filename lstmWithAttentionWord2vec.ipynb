{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "#!pip install tensorflow-gpu==2.0.0-alpha0\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import pandas as pd\n",
    "import logging\n",
    "import gensim\n",
    "from scipy import spatial\n",
    "\n",
    "orginal_sentences_oath_file = 'Data/Hebrew/SVLM_Hebrew_Wikipedia_Corpus.txt'\n",
    "tagged_sentences_path_file = 'Data/Hebrew/parsed.txt'\n",
    "csv_hebrew_sentences_path_file = 'Data/Hebrew/Hebrew_tagged_sentences.csv'\n",
    "NUM_EXAMPLES = 50000\n",
    "EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract subject for each tagged sentence\n",
    "def extract_sbj(sentences):\n",
    "    listoflists = []\n",
    "    sublist = []\n",
    "    for i in sentences:\n",
    "        if i.find(\"SBJ\") !=-1:\n",
    "            i = re.sub(r\"[^א-ת\\\"]+\", \" \", i)\n",
    "            if len(i)>3:\n",
    "                sublist.append(i)\n",
    "        elif i == '\\n':\n",
    "            listoflists.append(sublist)\n",
    "            sublist = []\n",
    "    return listoflists\n",
    "\n",
    "#flat the list of subject to one string\n",
    "def listToString(s):  \n",
    "    str1 = \" \" \n",
    "    return (str1.join(s))\n",
    "\n",
    "#match subject to orginal sentence\n",
    "def make_pairs(orginal_sentences,tagged_sentences,num_examples):\n",
    "    subjects = extract_sbj(tagged_sentences)\n",
    "    clear_lines = []\n",
    "    for tag, sentence in zip(subjects[:num_examples],orginal_sentences[:num_examples]):\n",
    "        clear_lines.append(listToString(tag) + '\\t' + sentence)\n",
    "    subject = []\n",
    "    sentences = []\n",
    "    for line in clear_lines:\n",
    "        line = line.split('\\t')\n",
    "        sentences.append(line[1])\n",
    "        subject.append(line[0])\n",
    "    return subject, sentences\n",
    "\n",
    "def make_csv_subject_sentence(orginal_sentences,tagged_sentences, csv_path,num_examples):\n",
    "    subjects, sentences = make_pairs(orginal_sentences,tagged_sentences,num_examples)\n",
    "    trainDF = pd.DataFrame()\n",
    "    trainDF['subject'] = subjects[:num_examples]\n",
    "    trainDF['sentence'] = sentences[:num_examples]\n",
    "    mask = (trainDF['subject'].str.len()>1)\n",
    "    trainDF = trainDF.loc[mask]\n",
    "    trainDF.to_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "orginal_sentences = open(orginal_sentences_oath_file).readlines()\n",
    "tagged_sentences = open(tagged_sentences_path_file).readlines()\n",
    "make_csv_subject_sentence(orginal_sentences,tagged_sentences,csv_hebrew_sentences_path_file,NUM_EXAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_hebrew_sentences_path_file,index_col=[0])\n",
    "NUM_EXAMPLES = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the unicode file to ascii\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence_Hebrew(w):\n",
    "    #w = unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    #w = re.sub(r\"([?.!,¿\\\"])\", r\" \\1 \", w)\n",
    "    #w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^א-ת\\\"]+\", \" \", w)\n",
    "\n",
    "    w = w.rstrip().strip()\n",
    "\n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the unicode file to ascii\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "    w = w.rstrip().strip()\n",
    "\n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> מבחינתי אפשר להעלות אותו לרשימת ההמתנה לשמוע הערות ואח\"כ להצבעה <end>\n"
     ]
    }
   ],
   "source": [
    "example_sentence = preprocess_sentence_Hebrew(\"מבחינתי אפשר להעלות אותו לרשימת ההמתנה לשמוע הערות ואח\\\"כ להצבעה\")\n",
    "print(example_sentence)\n",
    "example_sentence = [subject for subject in example_sentence.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_from_csv(csv_path, num_examples):\n",
    "    df = pd.read_csv(csv_path,index_col=[0])\n",
    "    subjects = [preprocess_sentence_Hebrew(subject) for subject in df['subject']]  \n",
    "    sentences = [preprocess_sentence_Hebrew(sentence) for sentence in df['sentence']] \n",
    "    subjects = [subject.split() for subject in subjects]\n",
    "    sentences = [sentence.split() for sentence in sentences]\n",
    "    return subjects, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects, sentences = create_dataset_from_csv(csv_hebrew_sentences_path_file, NUM_EXAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train, sentences_test, subjects_train, subjects_test =\\\n",
    "train_test_split(sentences, subjects, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "word_model = gensim.models.Word2Vec(subjects+sentences, size=EMBEDDING_DIM, min_count=1, window=5, iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2idx(word, word_model):\n",
    "    if word in word_model.wv.vocab:\n",
    "        return word_model.wv.vocab[word].index\n",
    "    else:\n",
    "        return 1 #default index for non-exsits in vec_model voacb\n",
    "    \n",
    "def idx2word(idx, word_model):\n",
    "  return word_model.wv.index2word[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(sentence, word_model):\n",
    "  for w in sentence:\n",
    "      print (\"%d ----> %s\" % (word2idx(w,word_model),w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_indexes(sentence,word_model,max_length_inp):\n",
    "    data_set = [word2idx(w,word_model) for w in sentence]\n",
    "    data_set = tf.keras.preprocessing.sequence.pad_sequences([data_set],max_length_inp, padding='post', value=1)\n",
    "    return data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create matrix of the dataset indexes \n",
    "def create_dataset_word2vec_matrix(sentences,vec_model,max_length_inp):\n",
    "    data_set = []\n",
    "    #creates train data set\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        data_set.append(list())\n",
    "        data_set[i] = ([word2idx(word,vec_model) for word in sentence])\n",
    "    data_set = tf.keras.preprocessing.sequence.pad_sequences(data_set,max_length_inp, padding='post', value=1)\n",
    "    return data_set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sentence_len, max_subjects_len  = max_length(sentences_train), max_length(subjects_train)\n",
    "x_train = create_dataset_word2vec_matrix(sentences_train,word_model,max_sentence_len)\n",
    "y_train = create_dataset_word2vec_matrix(subjects_train,word_model,max_subjects_len)\n",
    "x_test = sentences_test\n",
    "y_test = subjects_test\n",
    "max_length_inp, max_length_targ  = x_train.shape[1], y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ----> <start>\n",
      "233 ----> מבחינתי\n",
      "79 ----> אפשר\n",
      "821 ----> להעלות\n",
      "48 ----> אותו\n",
      "4239 ----> לרשימת\n",
      "10519 ----> ההמתנה\n",
      "1130 ----> לשמוע\n",
      "403 ----> הערות\n",
      "14250 ----> ואח\"כ\n",
      "1619 ----> להצבעה\n",
      "1 ----> <end>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[    0,   233,    79,   821,    48,  4239, 10519,  1130,   403,\n",
       "        14250,  1619,     1,     1,     1]], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert(example_sentence,word_model)\n",
    "sentence_to_indexes(example_sentence,word_model,max_length_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mishka/.local/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  \n",
      "/home/mishka/.local/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  import sys\n",
      "/home/mishka/.local/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = len(x_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(x_train)//BATCH_SIZE\n",
    "embedding_dim = EMBEDDING_DIM\n",
    "units = 1024\n",
    "pretrained_weights = word_model.wv.syn0\n",
    "vocab_size = word_model.wv.syn0.shape[0]\n",
    "emdedding_size = word_model.wv.syn0.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(len(y_train))\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 14])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, _ = next(iter(dataset))\n",
    "example_input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim,pretrained_weights, maxlen, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.enc_units = enc_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim,weights=[pretrained_weights],input_length=maxlen,trainable=True)\n",
    "    self.lstm = tf.keras.layers.LSTM(self.enc_units, return_sequences=True, return_state=True)\n",
    "\n",
    "  def call(self, x, forward_h, forward_c):\n",
    "    x = self.embedding(x)\n",
    "    output, st_forward_h, st_forward_c = self.lstm(x, initial_state = [forward_h, forward_c])\n",
    "    return output, st_forward_h, st_forward_c\n",
    "\n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_sz, self.enc_units)), tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 14, 1024)\n",
      "Encoder Hidden forward_h state shape: (batch size, units) (64, 1024)\n",
      "Encoder Hidden forward_c state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_size, emdedding_size, pretrained_weights, max_length_inp ,units, BATCH_SIZE)\n",
    "forward_h, forward_c = encoder.initialize_hidden_state()\n",
    "sample_output, forward_h, forward_c = encoder(example_input_batch, forward_h, forward_c)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden forward_h state shape: (batch size, units) {}'.format(forward_h.shape))\n",
    "print ('Encoder Hidden forward_c state shape: (batch size, units) {}'.format(forward_c.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "  def __init__(self, units):\n",
    "    super(BahdanauAttention, self).__init__()\n",
    "    self.W1 =  tf.keras.layers.Dense(units)\n",
    "    self.W2 =  tf.keras.layers.Dense(units)\n",
    "    self.V =  tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, forward_h, forward_c, values):\n",
    "    query =  tf.keras.layers.Concatenate()([forward_h, forward_c])\n",
    "\n",
    "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "    score = self.V(tf.nn.tanh(\n",
    "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "    context_vector = attention_weights * values\n",
    "\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "    \n",
    "    return context_vector, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, pretrained_weights, maxlen, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim,weights=[pretrained_weights],input_length=maxlen,trainable=True)\n",
    "    self.lstm = tf.keras.layers.LSTM(self.dec_units, return_sequences=True, return_state=True)\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # used for attention\n",
    "    self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "  def call(self, x, forward_h, forward_c, enc_output):\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "    context_vector, attention_weights = self.attention(forward_h, forward_c, enc_output)\n",
    "\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # passing the concatenated vector to the GRU\n",
    "    output, st_forward_h, st_forward_c = self.lstm(x)\n",
    "\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # output shape == (batch_size, vocab)\n",
    "    x = self.fc(output)\n",
    "    return x, st_forward_h, st_forward_c, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 14, 1)\n",
      "Decoder output shape: (batch_size, vocab size) (64, 21000)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(forward_h, forward_c, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))\n",
    "\n",
    "decoder = Decoder(vocab_size, emdedding_size, pretrained_weights, max_length_targ ,units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      forward_h, forward_c,sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, forward_h, forward_c):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_output, enc_forward_h, enc_forward_c = encoder(inp,forward_h, forward_c)\n",
    "\n",
    "    dec_forward_h, dec_forward_c = enc_forward_h, enc_forward_c\n",
    "    dec_input = tf.expand_dims([word_model.wv.vocab['<start>'].index] * BATCH_SIZE, 1)\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # passing enc_output to the decoder\n",
    "      predictions, dec_forward_h, dec_forward_c, _ = decoder(dec_input, dec_forward_h, dec_forward_c, enc_output)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1218 22:07:32.296124 140151206668096 ag_logging.py:145] Entity <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>: ValueError: Failed to parse source code of <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>, which Python reported as:\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "from __future__ import unicode_literals\n",
      "  def call(self, x, forward_h, forward_c, enc_output):\n",
      "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
      "    #context_vector, attention_weights = self.attention(forward_h, forward_c, enc_output)\n",
      "\n",
      "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
      "    x = self.embedding(x)\n",
      "\n",
      "#     # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
      "#     x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
      "\n",
      "    # passing the concatenated vector to the GRU\n",
      "    output, st_forward_h, st_forward_c = self.lstm(x)\n",
      "\n",
      "    # output shape == (batch_size * 1, hidden_size)\n",
      "    output = tf.reshape(output, (-1, output.shape[2]))\n",
      "\n",
      "    # output shape == (batch_size, vocab)\n",
      "    x = self.fc(output)\n",
      "    return x, st_forward_h, st_forward_c#, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>: ValueError: Failed to parse source code of <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>, which Python reported as:\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "from __future__ import unicode_literals\n",
      "  def call(self, x, forward_h, forward_c, enc_output):\n",
      "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
      "    #context_vector, attention_weights = self.attention(forward_h, forward_c, enc_output)\n",
      "\n",
      "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
      "    x = self.embedding(x)\n",
      "\n",
      "#     # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
      "#     x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
      "\n",
      "    # passing the concatenated vector to the GRU\n",
      "    output, st_forward_h, st_forward_c = self.lstm(x)\n",
      "\n",
      "    # output shape == (batch_size * 1, hidden_size)\n",
      "    output = tf.reshape(output, (-1, output.shape[2]))\n",
      "\n",
      "    # output shape == (batch_size, vocab)\n",
      "    x = self.fc(output)\n",
      "    return x, st_forward_h, st_forward_c#, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1218 22:07:32.845042 140151206668096 ag_logging.py:145] Entity <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>: ValueError: Failed to parse source code of <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>, which Python reported as:\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "from __future__ import unicode_literals\n",
      "  def call(self, x, forward_h, forward_c, enc_output):\n",
      "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
      "    #context_vector, attention_weights = self.attention(forward_h, forward_c, enc_output)\n",
      "\n",
      "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
      "    x = self.embedding(x)\n",
      "\n",
      "#     # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
      "#     x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
      "\n",
      "    # passing the concatenated vector to the GRU\n",
      "    output, st_forward_h, st_forward_c = self.lstm(x)\n",
      "\n",
      "    # output shape == (batch_size * 1, hidden_size)\n",
      "    output = tf.reshape(output, (-1, output.shape[2]))\n",
      "\n",
      "    # output shape == (batch_size, vocab)\n",
      "    x = self.fc(output)\n",
      "    return x, st_forward_h, st_forward_c#, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>: ValueError: Failed to parse source code of <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>, which Python reported as:\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "from __future__ import unicode_literals\n",
      "  def call(self, x, forward_h, forward_c, enc_output):\n",
      "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
      "    #context_vector, attention_weights = self.attention(forward_h, forward_c, enc_output)\n",
      "\n",
      "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
      "    x = self.embedding(x)\n",
      "\n",
      "#     # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
      "#     x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
      "\n",
      "    # passing the concatenated vector to the GRU\n",
      "    output, st_forward_h, st_forward_c = self.lstm(x)\n",
      "\n",
      "    # output shape == (batch_size * 1, hidden_size)\n",
      "    output = tf.reshape(output, (-1, output.shape[2]))\n",
      "\n",
      "    # output shape == (batch_size, vocab)\n",
      "    x = self.fc(output)\n",
      "    return x, st_forward_h, st_forward_c#, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1218 22:07:33.217220 140151206668096 ag_logging.py:145] Entity <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>: ValueError: Failed to parse source code of <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>, which Python reported as:\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "from __future__ import unicode_literals\n",
      "  def call(self, x, forward_h, forward_c, enc_output):\n",
      "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
      "    #context_vector, attention_weights = self.attention(forward_h, forward_c, enc_output)\n",
      "\n",
      "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
      "    x = self.embedding(x)\n",
      "\n",
      "#     # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
      "#     x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
      "\n",
      "    # passing the concatenated vector to the GRU\n",
      "    output, st_forward_h, st_forward_c = self.lstm(x)\n",
      "\n",
      "    # output shape == (batch_size * 1, hidden_size)\n",
      "    output = tf.reshape(output, (-1, output.shape[2]))\n",
      "\n",
      "    # output shape == (batch_size, vocab)\n",
      "    x = self.fc(output)\n",
      "    return x, st_forward_h, st_forward_c#, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>: ValueError: Failed to parse source code of <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>, which Python reported as:\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "from __future__ import unicode_literals\n",
      "  def call(self, x, forward_h, forward_c, enc_output):\n",
      "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
      "    #context_vector, attention_weights = self.attention(forward_h, forward_c, enc_output)\n",
      "\n",
      "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
      "    x = self.embedding(x)\n",
      "\n",
      "#     # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
      "#     x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
      "\n",
      "    # passing the concatenated vector to the GRU\n",
      "    output, st_forward_h, st_forward_c = self.lstm(x)\n",
      "\n",
      "    # output shape == (batch_size * 1, hidden_size)\n",
      "    output = tf.reshape(output, (-1, output.shape[2]))\n",
      "\n",
      "    # output shape == (batch_size, vocab)\n",
      "    x = self.fc(output)\n",
      "    return x, st_forward_h, st_forward_c#, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1218 22:07:33.575752 140151206668096 ag_logging.py:145] Entity <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>: ValueError: Failed to parse source code of <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>, which Python reported as:\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "from __future__ import unicode_literals\n",
      "  def call(self, x, forward_h, forward_c, enc_output):\n",
      "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
      "    #context_vector, attention_weights = self.attention(forward_h, forward_c, enc_output)\n",
      "\n",
      "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
      "    x = self.embedding(x)\n",
      "\n",
      "#     # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
      "#     x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
      "\n",
      "    # passing the concatenated vector to the GRU\n",
      "    output, st_forward_h, st_forward_c = self.lstm(x)\n",
      "\n",
      "    # output shape == (batch_size * 1, hidden_size)\n",
      "    output = tf.reshape(output, (-1, output.shape[2]))\n",
      "\n",
      "    # output shape == (batch_size, vocab)\n",
      "    x = self.fc(output)\n",
      "    return x, st_forward_h, st_forward_c#, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>: ValueError: Failed to parse source code of <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>, which Python reported as:\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "from __future__ import unicode_literals\n",
      "  def call(self, x, forward_h, forward_c, enc_output):\n",
      "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
      "    #context_vector, attention_weights = self.attention(forward_h, forward_c, enc_output)\n",
      "\n",
      "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
      "    x = self.embedding(x)\n",
      "\n",
      "#     # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
      "#     x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
      "\n",
      "    # passing the concatenated vector to the GRU\n",
      "    output, st_forward_h, st_forward_c = self.lstm(x)\n",
      "\n",
      "    # output shape == (batch_size * 1, hidden_size)\n",
      "    output = tf.reshape(output, (-1, output.shape[2]))\n",
      "\n",
      "    # output shape == (batch_size, vocab)\n",
      "    x = self.fc(output)\n",
      "    return x, st_forward_h, st_forward_c#, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1218 22:07:34.160496 140151206668096 ag_logging.py:145] Entity <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>: ValueError: Failed to parse source code of <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>, which Python reported as:\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "from __future__ import unicode_literals\n",
      "  def call(self, x, forward_h, forward_c, enc_output):\n",
      "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
      "    #context_vector, attention_weights = self.attention(forward_h, forward_c, enc_output)\n",
      "\n",
      "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
      "    x = self.embedding(x)\n",
      "\n",
      "#     # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
      "#     x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
      "\n",
      "    # passing the concatenated vector to the GRU\n",
      "    output, st_forward_h, st_forward_c = self.lstm(x)\n",
      "\n",
      "    # output shape == (batch_size * 1, hidden_size)\n",
      "    output = tf.reshape(output, (-1, output.shape[2]))\n",
      "\n",
      "    # output shape == (batch_size, vocab)\n",
      "    x = self.fc(output)\n",
      "    return x, st_forward_h, st_forward_c#, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>: ValueError: Failed to parse source code of <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>, which Python reported as:\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "from __future__ import unicode_literals\n",
      "  def call(self, x, forward_h, forward_c, enc_output):\n",
      "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
      "    #context_vector, attention_weights = self.attention(forward_h, forward_c, enc_output)\n",
      "\n",
      "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
      "    x = self.embedding(x)\n",
      "\n",
      "#     # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
      "#     x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
      "\n",
      "    # passing the concatenated vector to the GRU\n",
      "    output, st_forward_h, st_forward_c = self.lstm(x)\n",
      "\n",
      "    # output shape == (batch_size * 1, hidden_size)\n",
      "    output = tf.reshape(output, (-1, output.shape[2]))\n",
      "\n",
      "    # output shape == (batch_size, vocab)\n",
      "    x = self.fc(output)\n",
      "    return x, st_forward_h, st_forward_c#, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1218 22:07:34.616760 140151206668096 ag_logging.py:145] Entity <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>: ValueError: Failed to parse source code of <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>, which Python reported as:\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "from __future__ import unicode_literals\n",
      "  def call(self, x, forward_h, forward_c, enc_output):\n",
      "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
      "    #context_vector, attention_weights = self.attention(forward_h, forward_c, enc_output)\n",
      "\n",
      "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
      "    x = self.embedding(x)\n",
      "\n",
      "#     # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
      "#     x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
      "\n",
      "    # passing the concatenated vector to the GRU\n",
      "    output, st_forward_h, st_forward_c = self.lstm(x)\n",
      "\n",
      "    # output shape == (batch_size * 1, hidden_size)\n",
      "    output = tf.reshape(output, (-1, output.shape[2]))\n",
      "\n",
      "    # output shape == (batch_size, vocab)\n",
      "    x = self.fc(output)\n",
      "    return x, st_forward_h, st_forward_c#, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>: ValueError: Failed to parse source code of <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>, which Python reported as:\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "from __future__ import unicode_literals\n",
      "  def call(self, x, forward_h, forward_c, enc_output):\n",
      "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
      "    #context_vector, attention_weights = self.attention(forward_h, forward_c, enc_output)\n",
      "\n",
      "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
      "    x = self.embedding(x)\n",
      "\n",
      "#     # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
      "#     x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
      "\n",
      "    # passing the concatenated vector to the GRU\n",
      "    output, st_forward_h, st_forward_c = self.lstm(x)\n",
      "\n",
      "    # output shape == (batch_size * 1, hidden_size)\n",
      "    output = tf.reshape(output, (-1, output.shape[2]))\n",
      "\n",
      "    # output shape == (batch_size, vocab)\n",
      "    x = self.fc(output)\n",
      "    return x, st_forward_h, st_forward_c#, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1218 22:07:37.175570 140151206668096 optimizer_v2.py:979] Gradients does not exist for variables ['encoder/embedding/embeddings:0', 'encoder/lstm/kernel:0', 'encoder/lstm/recurrent_kernel:0', 'encoder/lstm/bias:0'] when minimizing the loss.\n",
      "W1218 22:07:37.847718 140151206668096 ag_logging.py:145] Entity <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>: ValueError: Failed to parse source code of <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>, which Python reported as:\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "from __future__ import unicode_literals\n",
      "  def call(self, x, forward_h, forward_c, enc_output):\n",
      "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
      "    #context_vector, attention_weights = self.attention(forward_h, forward_c, enc_output)\n",
      "\n",
      "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
      "    x = self.embedding(x)\n",
      "\n",
      "#     # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
      "#     x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
      "\n",
      "    # passing the concatenated vector to the GRU\n",
      "    output, st_forward_h, st_forward_c = self.lstm(x)\n",
      "\n",
      "    # output shape == (batch_size * 1, hidden_size)\n",
      "    output = tf.reshape(output, (-1, output.shape[2]))\n",
      "\n",
      "    # output shape == (batch_size, vocab)\n",
      "    x = self.fc(output)\n",
      "    return x, st_forward_h, st_forward_c#, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>: ValueError: Failed to parse source code of <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>, which Python reported as:\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "from __future__ import unicode_literals\n",
      "  def call(self, x, forward_h, forward_c, enc_output):\n",
      "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
      "    #context_vector, attention_weights = self.attention(forward_h, forward_c, enc_output)\n",
      "\n",
      "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
      "    x = self.embedding(x)\n",
      "\n",
      "#     # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
      "#     x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
      "\n",
      "    # passing the concatenated vector to the GRU\n",
      "    output, st_forward_h, st_forward_c = self.lstm(x)\n",
      "\n",
      "    # output shape == (batch_size * 1, hidden_size)\n",
      "    output = tf.reshape(output, (-1, output.shape[2]))\n",
      "\n",
      "    # output shape == (batch_size, vocab)\n",
      "    x = self.fc(output)\n",
      "    return x, st_forward_h, st_forward_c#, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1218 22:07:38.210074 140151206668096 ag_logging.py:145] Entity <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>: ValueError: Failed to parse source code of <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>, which Python reported as:\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "from __future__ import unicode_literals\n",
      "  def call(self, x, forward_h, forward_c, enc_output):\n",
      "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
      "    #context_vector, attention_weights = self.attention(forward_h, forward_c, enc_output)\n",
      "\n",
      "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
      "    x = self.embedding(x)\n",
      "\n",
      "#     # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
      "#     x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
      "\n",
      "    # passing the concatenated vector to the GRU\n",
      "    output, st_forward_h, st_forward_c = self.lstm(x)\n",
      "\n",
      "    # output shape == (batch_size * 1, hidden_size)\n",
      "    output = tf.reshape(output, (-1, output.shape[2]))\n",
      "\n",
      "    # output shape == (batch_size, vocab)\n",
      "    x = self.fc(output)\n",
      "    return x, st_forward_h, st_forward_c#, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>: ValueError: Failed to parse source code of <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>, which Python reported as:\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "from __future__ import unicode_literals\n",
      "  def call(self, x, forward_h, forward_c, enc_output):\n",
      "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
      "    #context_vector, attention_weights = self.attention(forward_h, forward_c, enc_output)\n",
      "\n",
      "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
      "    x = self.embedding(x)\n",
      "\n",
      "#     # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
      "#     x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
      "\n",
      "    # passing the concatenated vector to the GRU\n",
      "    output, st_forward_h, st_forward_c = self.lstm(x)\n",
      "\n",
      "    # output shape == (batch_size * 1, hidden_size)\n",
      "    output = tf.reshape(output, (-1, output.shape[2]))\n",
      "\n",
      "    # output shape == (batch_size, vocab)\n",
      "    x = self.fc(output)\n",
      "    return x, st_forward_h, st_forward_c#, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1218 22:07:38.565519 140151206668096 ag_logging.py:145] Entity <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>: ValueError: Failed to parse source code of <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>, which Python reported as:\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "from __future__ import unicode_literals\n",
      "  def call(self, x, forward_h, forward_c, enc_output):\n",
      "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
      "    #context_vector, attention_weights = self.attention(forward_h, forward_c, enc_output)\n",
      "\n",
      "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
      "    x = self.embedding(x)\n",
      "\n",
      "#     # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
      "#     x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
      "\n",
      "    # passing the concatenated vector to the GRU\n",
      "    output, st_forward_h, st_forward_c = self.lstm(x)\n",
      "\n",
      "    # output shape == (batch_size * 1, hidden_size)\n",
      "    output = tf.reshape(output, (-1, output.shape[2]))\n",
      "\n",
      "    # output shape == (batch_size, vocab)\n",
      "    x = self.fc(output)\n",
      "    return x, st_forward_h, st_forward_c#, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>: ValueError: Failed to parse source code of <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>, which Python reported as:\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "from __future__ import unicode_literals\n",
      "  def call(self, x, forward_h, forward_c, enc_output):\n",
      "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
      "    #context_vector, attention_weights = self.attention(forward_h, forward_c, enc_output)\n",
      "\n",
      "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
      "    x = self.embedding(x)\n",
      "\n",
      "#     # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
      "#     x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
      "\n",
      "    # passing the concatenated vector to the GRU\n",
      "    output, st_forward_h, st_forward_c = self.lstm(x)\n",
      "\n",
      "    # output shape == (batch_size * 1, hidden_size)\n",
      "    output = tf.reshape(output, (-1, output.shape[2]))\n",
      "\n",
      "    # output shape == (batch_size, vocab)\n",
      "    x = self.fc(output)\n",
      "    return x, st_forward_h, st_forward_c#, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1218 22:07:39.115697 140151206668096 ag_logging.py:145] Entity <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>: ValueError: Failed to parse source code of <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>, which Python reported as:\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "from __future__ import unicode_literals\n",
      "  def call(self, x, forward_h, forward_c, enc_output):\n",
      "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
      "    #context_vector, attention_weights = self.attention(forward_h, forward_c, enc_output)\n",
      "\n",
      "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
      "    x = self.embedding(x)\n",
      "\n",
      "#     # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
      "#     x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
      "\n",
      "    # passing the concatenated vector to the GRU\n",
      "    output, st_forward_h, st_forward_c = self.lstm(x)\n",
      "\n",
      "    # output shape == (batch_size * 1, hidden_size)\n",
      "    output = tf.reshape(output, (-1, output.shape[2]))\n",
      "\n",
      "    # output shape == (batch_size, vocab)\n",
      "    x = self.fc(output)\n",
      "    return x, st_forward_h, st_forward_c#, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>: ValueError: Failed to parse source code of <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>, which Python reported as:\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "from __future__ import unicode_literals\n",
      "  def call(self, x, forward_h, forward_c, enc_output):\n",
      "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
      "    #context_vector, attention_weights = self.attention(forward_h, forward_c, enc_output)\n",
      "\n",
      "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
      "    x = self.embedding(x)\n",
      "\n",
      "#     # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
      "#     x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
      "\n",
      "    # passing the concatenated vector to the GRU\n",
      "    output, st_forward_h, st_forward_c = self.lstm(x)\n",
      "\n",
      "    # output shape == (batch_size * 1, hidden_size)\n",
      "    output = tf.reshape(output, (-1, output.shape[2]))\n",
      "\n",
      "    # output shape == (batch_size, vocab)\n",
      "    x = self.fc(output)\n",
      "    return x, st_forward_h, st_forward_c#, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1218 22:07:39.596512 140151206668096 ag_logging.py:145] Entity <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>: ValueError: Failed to parse source code of <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>, which Python reported as:\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "from __future__ import unicode_literals\n",
      "  def call(self, x, forward_h, forward_c, enc_output):\n",
      "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
      "    #context_vector, attention_weights = self.attention(forward_h, forward_c, enc_output)\n",
      "\n",
      "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
      "    x = self.embedding(x)\n",
      "\n",
      "#     # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
      "#     x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
      "\n",
      "    # passing the concatenated vector to the GRU\n",
      "    output, st_forward_h, st_forward_c = self.lstm(x)\n",
      "\n",
      "    # output shape == (batch_size * 1, hidden_size)\n",
      "    output = tf.reshape(output, (-1, output.shape[2]))\n",
      "\n",
      "    # output shape == (batch_size, vocab)\n",
      "    x = self.fc(output)\n",
      "    return x, st_forward_h, st_forward_c#, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>: ValueError: Failed to parse source code of <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>, which Python reported as:\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "from __future__ import unicode_literals\n",
      "  def call(self, x, forward_h, forward_c, enc_output):\n",
      "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
      "    #context_vector, attention_weights = self.attention(forward_h, forward_c, enc_output)\n",
      "\n",
      "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
      "    x = self.embedding(x)\n",
      "\n",
      "#     # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
      "#     x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
      "\n",
      "    # passing the concatenated vector to the GRU\n",
      "    output, st_forward_h, st_forward_c = self.lstm(x)\n",
      "\n",
      "    # output shape == (batch_size * 1, hidden_size)\n",
      "    output = tf.reshape(output, (-1, output.shape[2]))\n",
      "\n",
      "    # output shape == (batch_size, vocab)\n",
      "    x = self.fc(output)\n",
      "    return x, st_forward_h, st_forward_c#, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1218 22:07:40.088509 140151206668096 ag_logging.py:145] Entity <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>: ValueError: Failed to parse source code of <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>, which Python reported as:\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "from __future__ import unicode_literals\n",
      "  def call(self, x, forward_h, forward_c, enc_output):\n",
      "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
      "    #context_vector, attention_weights = self.attention(forward_h, forward_c, enc_output)\n",
      "\n",
      "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
      "    x = self.embedding(x)\n",
      "\n",
      "#     # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
      "#     x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
      "\n",
      "    # passing the concatenated vector to the GRU\n",
      "    output, st_forward_h, st_forward_c = self.lstm(x)\n",
      "\n",
      "    # output shape == (batch_size * 1, hidden_size)\n",
      "    output = tf.reshape(output, (-1, output.shape[2]))\n",
      "\n",
      "    # output shape == (batch_size, vocab)\n",
      "    x = self.fc(output)\n",
      "    return x, st_forward_h, st_forward_c#, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>: ValueError: Failed to parse source code of <bound method Decoder.call of <__main__.Decoder object at 0x7f76f03d8c50>>, which Python reported as:\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "from __future__ import unicode_literals\n",
      "  def call(self, x, forward_h, forward_c, enc_output):\n",
      "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
      "    #context_vector, attention_weights = self.attention(forward_h, forward_c, enc_output)\n",
      "\n",
      "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
      "    x = self.embedding(x)\n",
      "\n",
      "#     # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
      "#     x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
      "\n",
      "    # passing the concatenated vector to the GRU\n",
      "    output, st_forward_h, st_forward_c = self.lstm(x)\n",
      "\n",
      "    # output shape == (batch_size * 1, hidden_size)\n",
      "    output = tf.reshape(output, (-1, output.shape[2]))\n",
      "\n",
      "    # output shape == (batch_size, vocab)\n",
      "    x = self.fc(output)\n",
      "    return x, st_forward_h, st_forward_c#, attention_weights\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1218 22:07:42.820490 140151206668096 optimizer_v2.py:979] Gradients does not exist for variables ['encoder/embedding/embeddings:0', 'encoder/lstm/kernel:0', 'encoder/lstm/recurrent_kernel:0', 'encoder/lstm/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 8.5458\n",
      "Epoch 1 Batch 100 Loss 1.5772\n",
      "Epoch 1 Batch 200 Loss 1.3370\n",
      "Epoch 1 Batch 300 Loss 1.5433\n",
      "Epoch 1 Batch 400 Loss 1.2872\n",
      "Epoch 1 Loss 1.6460\n",
      "Time taken for 1 epoch 70.47471451759338 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.2118\n",
      "Epoch 2 Batch 100 Loss 1.3415\n",
      "Epoch 2 Batch 200 Loss 1.2485\n",
      "Epoch 2 Batch 300 Loss 1.4179\n",
      "Epoch 2 Batch 400 Loss 1.2223\n",
      "Epoch 2 Loss 1.2656\n",
      "Time taken for 1 epoch 55.96099400520325 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.1942\n",
      "Epoch 3 Batch 100 Loss 1.2818\n",
      "Epoch 3 Batch 200 Loss 1.2342\n",
      "Epoch 3 Batch 300 Loss 1.3493\n",
      "Epoch 3 Batch 400 Loss 1.1932\n",
      "Epoch 3 Loss 1.2319\n",
      "Time taken for 1 epoch 55.497955083847046 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.1780\n",
      "Epoch 4 Batch 100 Loss 1.2388\n",
      "Epoch 4 Batch 200 Loss 1.2142\n",
      "Epoch 4 Batch 300 Loss 1.3065\n",
      "Epoch 4 Batch 400 Loss 1.1626\n",
      "Epoch 4 Loss 1.2099\n",
      "Time taken for 1 epoch 57.109793186187744 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.1586\n",
      "Epoch 5 Batch 100 Loss 1.1969\n",
      "Epoch 5 Batch 200 Loss 1.2059\n",
      "Epoch 5 Batch 300 Loss 1.2764\n",
      "Epoch 5 Batch 400 Loss 1.1448\n",
      "Epoch 5 Loss 1.1915\n",
      "Time taken for 1 epoch 55.84993600845337 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.1430\n",
      "Epoch 6 Batch 100 Loss 1.1656\n",
      "Epoch 6 Batch 200 Loss 1.1831\n",
      "Epoch 6 Batch 300 Loss 1.2578\n",
      "Epoch 6 Batch 400 Loss 1.1341\n",
      "Epoch 6 Loss 1.1754\n",
      "Time taken for 1 epoch 56.46667122840881 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.1305\n",
      "Epoch 7 Batch 100 Loss 1.1533\n",
      "Epoch 7 Batch 200 Loss 1.1633\n",
      "Epoch 7 Batch 300 Loss 1.2473\n",
      "Epoch 7 Batch 400 Loss 1.1312\n",
      "Epoch 7 Loss 1.1616\n",
      "Time taken for 1 epoch 56.5771803855896 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.1267\n",
      "Epoch 8 Batch 100 Loss 1.1410\n",
      "Epoch 8 Batch 200 Loss 1.1488\n",
      "Epoch 8 Batch 300 Loss 1.2408\n",
      "Epoch 8 Batch 400 Loss 1.1236\n",
      "Epoch 8 Loss 1.1540\n",
      "Time taken for 1 epoch 56.17387413978577 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.1155\n",
      "Epoch 9 Batch 100 Loss 1.1253\n",
      "Epoch 9 Batch 200 Loss 1.1419\n",
      "Epoch 9 Batch 300 Loss 1.2355\n",
      "Epoch 9 Batch 400 Loss 1.1222\n",
      "Epoch 9 Loss 1.1472\n",
      "Time taken for 1 epoch 56.02090620994568 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 1.1133\n",
      "Epoch 10 Batch 100 Loss 1.1160\n",
      "Epoch 10 Batch 200 Loss 1.1405\n",
      "Epoch 10 Batch 300 Loss 1.2368\n",
      "Epoch 10 Batch 400 Loss 1.1144\n",
      "Epoch 10 Loss 1.1445\n",
      "Time taken for 1 epoch 56.23127365112305 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_forward_h, enc_forward_c = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_forward_h, enc_forward_c)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                     batch,\n",
    "                                                     batch_loss.numpy()))\n",
    "  # saving (checkpoint) the model every 2 epochs\n",
    "  if (epoch + 1) % 2 == 0:\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "    inputs = sentence_to_indexes(sentence,word_model, max_length_inp)\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "    forward_h  = tf.zeros((1, units))\n",
    "    forward_c  = tf.zeros((1, units))\n",
    "    backward_h = tf.zeros((1, units))\n",
    "    backward_c = tf.zeros((1, units))\n",
    "    print(inputs.shape)\n",
    "\n",
    "    enc_out, enc_forward_h, enc_forward_c = encoder(inputs, forward_h, forward_c)\n",
    "\n",
    "    dec_forward_h, dec_forward_c = enc_forward_h, enc_forward_c\n",
    "\n",
    "\n",
    "    dec_input = tf.expand_dims([word_model.wv.vocab['<start>'].index], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_forward_h, dec_forward_c, attention_weights = decoder(dec_input, dec_forward_h, dec_forward_c,enc_out)\n",
    "        predictions, dec_forward_h, dec_forward_c = decoder(dec_input, dec_forward_h, dec_forward_c,enc_out)\n",
    "\n",
    "        # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "        # print(\"evaluate attention_plot[\",t,\"]\",attention_plot[t])\n",
    "\n",
    "        \n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        \n",
    "        if word_model.wv.index2word[predicted_id] != '<end>':\n",
    "            result += word_model.wv.index2word[predicted_id] + ' '\n",
    "\n",
    "        if word_model.wv.index2word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 1)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KDtree_nearest(test_sentence,result):\n",
    "    A = [word_model[word] for word in test_sentence.split()]\n",
    "    tree = spatial.KDTree(A)\n",
    "    word_result = result.split()\n",
    "    a = word_model[word_result[0]]\n",
    "    index = tree.query(a)[1]\n",
    "    return test_sentence.split()[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "    result = KDtree_nearest(sentence,result)\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted subject: {}'.format(result))\n",
    "    sentence = sentence[::-1]\n",
    "    result = result[::-1]\n",
    "    sentence_splited = sentence.split(' ')\n",
    "    #to fix the hebrew changes\n",
    "    sentence_splited.reverse()\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence_splited, result.split(' '))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # restoring the latest checkpoint in checkpoint_dir\n",
    "# checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 14)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-ed6b3c1e616b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"הוא לא יודע מה עובר עליי\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-42-29a368460da4>\u001b[0m in \u001b[0;36mtag\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKDtree_nearest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted subject: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-1b08fbe91d76>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length_targ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_forward_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_forward_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_forward_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_forward_c\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menc_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_forward_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_forward_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_forward_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_forward_c\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menc_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "test_sentence = \"הוא לא יודע מה עובר עליי\"\n",
    "result = tag(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
